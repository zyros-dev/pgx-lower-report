% TODO 
% 2. add a table of the MLIR dialect, and what we had to change 
% 3. add a test suite table for the .sql files in the regression. 
% 4 ok, define upcasting. 
% 5. talk about how runtime functions were linked by using LingoDB's infrastructure. 
% 6. when error, dump progress. 

\chapter{Method}\label{ch:project}
In section~\ref{sec:design} the overarching design is described,
then section~\ref{sec:implementation} goes over the implementation.

\section{Design}\label{sec:design}
The first decision is which database and which compiler this project should use.
Something with strong extension support, wide-spread usage, high performance,
and a volcano execution model is needed as a base. For the compiler,
it would be ideal if they already use a similar interface to the target database
when they parse SQL, and have promising results in their performance. This
removes HyPer, Umbra, and System R, and leaves Mutable and LingoDB. LingoDB
parses its inputs with \texttt{pg\_query}, so it matches with PostgreSQL.

As a result, PostgreSQL and LingoDB were chosen. PostgreSQL offers strong support
for extensions, and it is possible to override its execution engine using runtime
hooks. An example of this is TimescaleDB (now TigerData) \cite{timescaledb}, which was explored in
section~\ref{sec:postgresql-related}. The primary challenge with this is that LingoDB is a columnar,
in-memory database, so adjustments will be needed. Furthermore, LingoDB does
not support indexes, which can make the benchmarks against PostgreSQL unfair.
Another detail is that LingoDB's newer versions contain a large number of
features and optimisations that is not relevant to us, so to simplify implementation
effort the 2022 version was used from their initial paper.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{figures/system_design.drawio.pdf}
	\caption{System design with labels of component sources.}
	\label{fig:overall-system-design}
\end{figure}

LingoDB was integrated into PostgreSQL as seen in figure~\ref{fig:overall-system-design}.
The blue represents PostgreSQL components, with the pipeline on the left being
the whole of PostgreSQL. A query reaches the runtime hooks, which gets analyzed
by a hand-written analyzer for whether the query can be execution, and then parsed.
These hand writte components are annotated in light-peach.
This goes through the code LingoDB created, but with custom runtime hooks and
other small edits, annotated with green. Finally this is compiled into
LLVM IR, which has the runtime hooks for reading from PostgreSQL embedded inside.

In the case that a query fails, the system should still support returning the
results and gracefully roll over to PostgreSQL. This was done by ensuring the
AST parser entrance has a try-catch pattern that routes back to PostgreSQL
even in failures. However, this does not protect from system panics such as
segmentation faults.

The most time-consuming part of this is expected to be the AST Parser section,
because it will be receiving the plan tree with the optimisations from PostgreSQL.
LingoDB was designed to parse the query tree, which would come from the
"Parser" stage in figure~\ref{fig:overall-system-design}. 18 plan nodes and 14
expression nodes were implemented.

The final goal here is to support the TPC-H query set.
To drive this implementation, a test-driven approach was used where PostgreSQL's
\texttt{pg\_regress} module added support for creating SQL queries and defining
expected outputs. With this, a test set of basic queries was created which built
up to TPC-H queries. This allowed progressive node implementation during
development, and a quick way to validate changes are safe.

Node implementation ordering followed the dependency analysis. Foundational
nodes such as the sequential scan and projection are in virtually every query,
while other nodes build on top. By implementing in the dependency order, each new
node could be tested using the previously implemented nodes, and bugs can be
isolated.

\section{Implementation}\label{sec:implementation}

The primary system this project was developed on was a x86\_64 CPU (Ryzen 3600)
and on Ubuntu 25.04. The database was not tested on MacOS or Windows, and this
may lead to issues when installing it independently.

%===============================================================================
\subsection{Integrating LingoDB to PostgreSQL}\label{subsec:integrating-lingodb}
The project was started from \url{https://github.com/mkindahl/pg_extension},
then \texttt{ExecutorRun\_hook} inside of executor.h in PostgreSQL
was used \url{https://doxygen.postgresql.org/executor_8h_source.html} as the
entrance. Within PostgreSQL there are some surrounding steps since the intention
is not usually to replace the entire executor with these hooks, so the memory
context had to be activated and switched into.

Next, the \texttt{QueryDesc} pointer, which contains the query request,
was to be passed through to \texttt{C++}. This causes a design decision. Good practice
here is to use smart pointers to prevent memory leaks, but this object is large
and the source of truth about the request. Furthermore, the memory is handled by
the PostgreSQL memory contexts. It was decided that these objects will remain
as raw pointers, causing the \texttt{C++} to break conventions.

LingoDB was installed as a git submodule and set to a read-only permission.
This was maintained for reference purposes only, and the compilation phases
would be extracted. LingoDB used LLVM 14, and was upgraded to LLVM 20 to
modernise it and slightly better support with \texttt{C++20} (some workarounds were
required with LLVM 14 that could be skipped with LLVM 20). However,
since this is the C++ API for LLVM, a large amount of the LingoDB code
had to be adjusted to compile.

%===============================================================================
\subsection{Logging infrastructure}\label{subsec:logging}
PostgreSQL has its own logging infrastructure that routes through its \texttt{elog}
command, but it was decided that a two-layer logging infrastructure was required.
The first layer is the level, (\texttt{DEBUG}, \texttt{IR}, \texttt{TRACE}, \texttt{WARNING\_LEVEL},
\texttt{ERROR\_LEVEL}, and more), and the second represents which layer of the design
the log is inside of (\texttt{AST\_TRANSLATE}, \texttt{RELALG\_LOWER}, \texttt{DB\_LOWER}, and more).
This meant if the AST translation was being worked on, all the logs in only that
section of the codebase could be enabled. The core benefit of this is that
the logs are lengthy so it becomes easier to navigate.

An issue that was encountered was that the LLVM/MLIR logs would route through
stderr, and this caused difficult to debug issues until the hook was found
to redirect this into \texttt{elog} as well. Subsection\~ref{subsec:debugging} will
explore one of the workarounds that was needed at this stage.

Lastly, for error handling mostly \texttt{std::runtime\_error} was utilised. This served
as a global way to log the stack trace and roll back to PostgreSQL's execution.
There initially was an implementation of error handling with severity levels
and messages, but the simplicity of a single command that rolled back to
PostgreSQL was more generally useful.

%===============================================================================
\subsection{Debugging Support}\label{subsec:debugging}
An important property of PostgreSQL is that each client connection creates a new
process. This means there are several layers to claw through to debug issues.
First, is the PostgreSQL postmaster, then the client connection, then within
that is the runtime hook entrance, which leads to $C++$, and inside $C++$
we will be compiling into a JIT runtime, and the bugs can happen inside there.
This poses a challenge for how to debug problems such as segmentation faults and
errors without any logging.

% messy paragraph
This was solved with a combination of the regression tests, unit testing, and
a script to connect \texttt{gdb} to dump the stack. The regression tests were already
explored, but the unit tests consist of testing anything unconnected to PostgreSQL.
The issue is that this extension creates a \texttt{pgx\_lower.so} which is installed
within PostgreSQL, then the PostgreSQL libraries are used from inside there.
This means if we run without being inside of PostgreSQL, no psql libaries can
be used. As a result, unit tests can only test MLIR functions. Most of the
unit tests were highly situational, and are used when a proper interactive GDB
connection was required within the IDE. Furthermore, unit tests allow the \texttt{stderr}
to be visible, which assists greatly with MLIR/LLVM errors that go to \texttt{stderr}
and nowhere else.

For the stack-dumping, a script was written, \texttt{debug-query.sh} which proved to
be the most useful approach for complex issues. It has the ability to create a
psql connection, git the process ID of the client connection, then connect GDB,
run a desired query, and dump the stack trace. In this way, the majority of
errors were tackled.

%===============================================================================
\subsection{Data Types}\label{subsec:data-types}
PostgreSQL has a large set of data types
(\url{https://www.postgresql.org/docs/current/datatype.html}),
and LingoDB has significantly less. However, for TPC-H we only require a subset
of these. Table ~\ref{tab:lingodb-type-capabilities}
shows which of the LingoDB types are used,
and table~\ref{tab:type-mapping} shows the type mappings. The two primary
workarounds that were implemented was for decimals and the various types of strings.
For decimals, i128 is enough precision for most of the TPC-H tests, and is what
LingoDB was using. However, adjustments had to be made to ensure impossible
to allocate values do not appear, so the precision was capped at \texttt{<32, 6>}
That is, 32 digits in the integer part, 6 digits in the decimal places.

For the date types, a comprimise was made that when it receives an interval
type with a months column, it will turn this into days and introduce errors.
However, since the TPC-H queries never use month intervals, this is acceptable.

\begin{table}[H]
	\centering
	\small
	\begin{tabular}{llp{4.5cm}}
		\toprule
		\textbf{DB Dialect Type}            & \textbf{LLVM Type}    & \textbf{Used by pgx-lower?} \\
		\midrule
		\texttt{!db.date<day>}              & \texttt{i64}          & Yes                         \\
		\texttt{!db.date<millisecond>}      & \texttt{i64}          & No                          \\
		\texttt{!db.timestamp<second>}      & \texttt{i64}          & Only if typmod specifies    \\
		\texttt{!db.timestamp<millisecond>} & \texttt{i64}          & Only if typmod specifies    \\
		\texttt{!db.timestamp<microsecond>} & \texttt{i64}          & Yes (default)               \\
		\texttt{!db.timestamp<nanosecond>}  & \texttt{i64}          & Only if typmod specifies    \\
		\texttt{!db.interval<months>}       & \texttt{i64}          & No                          \\
		\texttt{!db.interval<daytime>}      & \texttt{i64}          & Yes                         \\
		\texttt{!db.char<N>}                & \texttt{\{ptr, i32\}} & No (uses !db.string)        \\
		\texttt{!db.string}                 & \texttt{\{ptr, i32\}} & Yes                         \\
		\texttt{!db.decimal<p,s>}           & \texttt{i128}         & Yes                         \\
		\texttt{!db.nullable<T>}            & \texttt{\{T, i1\}}    & Yes                         \\
		\bottomrule
	\end{tabular}
	\caption{LingoDB type system full capabilities}
	\label{tab:lingodb-type-capabilities}
\end{table}

\begin{table}[H]
	\centering
	\small
	\begin{tabular}{lll}
		\toprule
		\textbf{PostgreSQL Type} & \textbf{DB Dialect Type}               & \textbf{LLVM Type}    \\
		\midrule
		\multicolumn{3}{l}{\textit{Integers}}                                                     \\
		\cmidrule{2-3}
		INT2 (SMALLINT)          & \texttt{i16}                           & \texttt{i16}          \\
		INT4 (INTEGER)           & \texttt{i32}                           & \texttt{i32}          \\
		INT8 (BIGINT)            & \texttt{i64}                           & \texttt{i64}          \\
		\addlinespace
		\multicolumn{3}{l}{\textit{Floating Point}}                                               \\
		\cmidrule{2-3}
		FLOAT4 (REAL)            & \texttt{f32}                           & \texttt{f32}          \\
		FLOAT8 (DOUBLE)          & \texttt{f64}                           & \texttt{f64}          \\
		\addlinespace
		\multicolumn{3}{l}{\textit{Boolean}}                                                      \\
		\cmidrule{2-3}
		BOOL                     & \texttt{i1}                            & \texttt{i1}           \\
		\addlinespace
		\multicolumn{3}{l}{\textit{String Types}}                                                 \\
		\cmidrule{2-3}
		TEXT / VARCHAR / BPCHAR  & \texttt{!db.string}                    & \texttt{\{ptr, i32\}} \\
		BYTEA                    & \texttt{!db.string}                    & \texttt{\{ptr, i32\}} \\
		\addlinespace
		\multicolumn{3}{l}{\textit{Numeric}}                                                      \\
		\cmidrule{2-3}
		NUMERIC(p,s)             & \texttt{!db.decimal<p,s>}              & \texttt{i128}         \\
		\addlinespace
		\multicolumn{3}{l}{\textit{Date/Time}}                                                    \\
		\cmidrule{2-3}
		DATE                     & \texttt{!db.date<day>}                 & \texttt{i64}          \\
		TIMESTAMP                & \texttt{!db.timestamp<s|ms|$\mu$s|ns>} & \texttt{i64}          \\
		INTERVAL                 & \texttt{!db.interval<daytime>}         & \texttt{i64}          \\
		\addlinespace
		\multicolumn{3}{l}{\textit{Nullable}}                                                     \\
		\cmidrule{2-3}
		Any nullable column      & \texttt{!db.nullable<T>}               & \texttt{\{T, i1\}}    \\
		\bottomrule
	\end{tabular}
	\caption{PostgreSQL type translation through DB dialect to LLVM}
	\label{tab:type-mapping}
\end{table}

This defines most of the supporting details, and the main two components of
the implementation can be described: the runtime patterns and the plan tree
translation.

%===============================================================================
\subsection{Runtime patterns}\label{subsec:runtime-patterns}
Runtime functions are used in LingoDB for difficult to implement methods in
LLVM, such as a sort algorithm. \texttt{pgx-lower} implemented reading tuples from
PostgreSQL, storing them as a result so that they can be streamed one by one,
adjusted several runtime implementations from LingoDB, and changed the sort and
hashtable implementations to rely on the PostgreSQL API rather than standard
collections.

Figure~\ref{fig:runtime-functions} shows the high-level components in a
runtime function. During SQL translation to MLIR, the frontend creates
\texttt{db.runtimecall} operations with a function name and arguments.
These operations are registered in the runtime function registry, which maps
each function name to either a \texttt{FunctionSpec} containing the mangled
C++ symbol name, or a custom lowering lambda. During the DBToStd
lowering pass, the \texttt{RuntimeCallLowering} pattern looks up each runtime
call in the registry and replaces it with a \texttt{func.call} operation
targeting the mangled C++ function. The JIT engine then links these function
calls to the actual compiled C++ runtime implementations, which handle
PostgreSQL-specific operations like tuple access, sorting via
\texttt{tuplesort}, and hash table management using PostgreSQL's memory
contexts. This pattern allows complex operations to be implemented once in C++
and reused across all queries, while maintaining type safety and null handling
semantics through the MLIR type system.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{figures/runtime-functions.drawio.pdf}
	\caption{System design with labels of component sources.}
	\label{fig:runtime-functions}
\end{figure}

The PostgreSQL runtime implements zero-copy tuple access for reading and
result accumulation for output. When scanning a table,
\texttt{openpostgrestable()} creates a heap scan
using \texttt{heapbeginscan()}, and \texttt{readnexttuplefromtable()} stores a
pointer (not a copy) to each tuple in the global
\texttt{gcurrenttuplepassthrough} structure. JIT code
extracts fields via \texttt{extractfield()}, which uses \texttt{heapgetattr()}
and converts PostgreSQL \texttt{Datum} values to native types. For results,
\texttt{tablebuilderadd()} accumulates computed values as \texttt{Datum}
arrays in \texttt{ComputedResultStorage}. When a result tuple
completes, \texttt{addtupletoresult()} streams it back through
PostgreSQL's \texttt{TupleStreamer} by populating a \texttt{TupleTableSlot} and
calling the destination receiver, enabling direct integration with
PostgreSQL's tuple pipeline.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{figures/pgsql-runtime.drawio.pdf}
	\caption{PostgreSQLRuntime.h component design}
	\label{fig:pgsql-runtime}
\end{figure}

The PostgreSQL runtime allows the JIT runtime to read from the psql tables, and
the design of it is visible in Figure~\ref{fig:pgsql-runtime}.
Generated JIT code invokes runtime functions implemented in the C++ layer,
including table operations (\texttt{open\_psql\_table}), field extraction
(\texttt{extract\_field<T>}), result building (\texttt{table\_builder\_add}),
and type conversions between PostgreSQL's \texttt{Datum} representation and
native types. These runtime functions interface with PostgreSQL's C API layer,
which handles heap access for reading tuples, memory management through
PostgreSQL's context system, and tuple streaming for returning results to the
executor. An important part is that when tuples are read from Postgres,
only the pointers are stored within the C++ storage layer to maintain
zero-copy semantics.

Once stored, the JIT code can read from the batch and
stream tuples back through the output pipeline as well. Streaming the tuples
out from JIT means that the entire table does not build up in RAM,
and instead tuples are returned one by one. This was tested by doing larger table
scans as avoiding this buildup is essential.

LingoDB's sort and hashtable runtimes were relying on \texttt{std::sort} and
\texttt{std::unordered\_map} respectively. This is problematic because as an
on-disk database we need to handle disk spillage in these scenarios. Rather than
reinventing these, leaning on psql's implementation of these solves these issues
and creates a blueprint for further implementations.

Most of the LingoDB lowerings bake metadata (such as table names) into the compiled
binary by JSON-encoding it as a string. Instead of that, for the sort and
hash table runtimes a specification pointer was used. Inside the plan translation
stage, a struct was built and allocated with the transaction memory context, then
the pointer to this was baked into the compiled binary instead. This enabled
these runtimes to trigger without doing JSON deserialisation, and creating the
operations them could skip this stage. This is something that a regular
compiler would be incapable of doing, because the binary needs to be a standalone
program, but in this context it can be relied upon.

%===============================================================================
\subsection{Plan Tree Translation}\label{subsec:ast-patterns}
The plan tree translation converts PostgreSQL's execution plan nodes into
RelAlg MLIR operations. Figure~\ref{fig:ast-impl} shows where this fits
into the broader design. Within the AST Parser component, we have an
entry that reads the PostgreSQL tag on the node that reads which type of plan
it is, then a recursive descent parser starts translating. Within
each translation function, the pattern is typically that the children
of the plan is translated (i.e. post-order traversal), then the definition
of the node is established in our context, the translation into the MLIR
relational algebra dialect is done, and a "translation result" is returned.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.7]{figures/ast-impl.drawio.pdf}
	\caption{AST translation design and high-level steps}
	\label{fig:ast-impl}
\end{figure}

The translation functions follow a consistent pattern, as shown in
Listing~\ref{lst:plan-translate-methods}. Each function takes the query
context and a PostgreSQL plan node pointer, performs the translation, and
returns a \texttt{TranslationResult}. The concept here is that the \texttt{QueryCtxT}
object is pushed down, and when it is mutated a new one is allocated and pushed
to the child, while the \texttt{TranslationResult}s flow upwards and represent
the output of each node. This, in theory, grants strong type-correctness. However,
it is not strictly followed.

\begin{lstlisting}[
	caption=Plan node translation method signatures. The expression nodes follow the same pattern.,
	label=lst:plan-translate-methods,
	breaklines=true
]
auto translate_plan_node(QueryCtxT& ctx, Plan* plan) -> TranslationResult;
auto translate_seq_scan(QueryCtxT& ctx, SeqScan* seqScan) -> TranslationResult;
auto translate_index_scan(QueryCtxT& ctx, IndexScan* indexScan) -> TranslationResult;
auto translate_index_only_scan(QueryCtxT& ctx, IndexOnlyScan* indexOnlyScan) -> TranslationResult;
auto translate_bitmap_heap_scan(QueryCtxT& ctx, BitmapHeapScan* bitmapScan) -> TranslationResult;
auto translate_agg(QueryCtxT& ctx, const Agg* agg) -> TranslationResult;
auto translate_sort(QueryCtxT& ctx, const Sort* sort) -> TranslationResult;
auto translate_limit(QueryCtxT& ctx, const Limit* limit) -> TranslationResult;
auto translate_gather(QueryCtxT& ctx, const Gather* gather) -> TranslationResult;
auto translate_gather_merge(QueryCtxT& ctx, const GatherMerge* gatherMerge) -> TranslationResult;
auto translate_merge_join(QueryCtxT& ctx, MergeJoin* mergeJoin) -> TranslationResult;
auto translate_hash_join(QueryCtxT& ctx, HashJoin* hashJoin) -> TranslationResult;
auto translate_hash(QueryCtxT& ctx, const Hash* hash) -> TranslationResult;
auto translate_nest_loop(QueryCtxT& ctx, NestLoop* nestLoop) -> TranslationResult;
auto translate_material(QueryCtxT& ctx, const Material* material) -> TranslationResult;
auto translate_memoize(QueryCtxT& ctx, const Memoize* memoize) -> TranslationResult;
auto translate_subquery_scan(QueryCtxT& ctx, SubqueryScan* subqueryScan) -> TranslationResult;
auto translate_cte_scan(QueryCtxT& ctx, const CteScan* cteScan) -> TranslationResult;
\end{lstlisting}

The 14 expression node types are documented in
Table~\ref{tab:expr-nodes}, and the 18 plan node types in Table~\ref{tab:plan-nodes}.
These will be explained more specifically in the subsections.

\begin{table}[H]
	\centering
	\small
	\begin{tabular}{lllp{6cm}}
		\toprule
		\textbf{File} & \textbf{Node Tag}             & \textbf{Implementation Note}                       \\
		\midrule
		basic         & \texttt{T\_BoolExpr}          & Boolean AND/OR/NOT - with short-circuit evaluation \\
		basic         & \texttt{T\_Const}             & Constant value - converts Datum to MLIR constant   \\
		basic         & \texttt{T\_CoalesceExpr}      & COALESCE(...) - first non-null using if-else       \\
		basic         & \texttt{T\_CoerceViaIO}       & Type coercion - calls PostgreSQL cast functions    \\
		basic         & \texttt{T\_NullTest}          & IS NULL checks - generates nullable type tests     \\
		basic         & \texttt{T\_Param}             & Query parameter - looks up from context            \\
		basic         & \texttt{T\_RelabelType}       & Type relabeling - transparent wrapper              \\
		basic         & \texttt{T\_Var}               & Column reference - resolves varattno to column     \\
		complex       & \texttt{T\_Aggref}            & Aggregate functions - creates AggregationOp        \\
		complex       & \texttt{T\_CaseExpr}          & CASE WHEN ... END - nested if-else operations      \\
		complex       & \texttt{T\_ScalarArrayOpExpr} & IN/ANY/ALL with arrays - loops over elements       \\
		complex       & \texttt{T\_SubPlan}           & Subquery expression - materializes and uses result \\
		functions     & \texttt{T\_FuncExpr}          & Function calls - maps PostgreSQL functions to MLIR \\
		operators     & \texttt{T\_OpExpr}            & Binary/unary operators                             \\
		\bottomrule
	\end{tabular}
	\caption{Expression node translations}
	\label{tab:expr-nodes}
\end{table}

\begin{table}[H]
	\centering
	\small
	\begin{tabular}{lllp{6cm}}
		\toprule
		\textbf{File} & \textbf{Node Tag}           & \textbf{Implementation Note}                          \\
		\midrule
		agg           & \texttt{T\_Agg}             & Aggregation - AggregationOp with grouping keys        \\
		joins         & \texttt{T\_HashJoin}        & Hash join - InnerJoinOp with hash implementation      \\
		joins         & \texttt{T\_MergeJoin}       & Merge join - InnerJoinOp with merge semantics         \\
		joins         & \texttt{T\_NestLoop}        & Nested loop join - CrossProductOp or InnerJoinOp      \\
		scans         & \texttt{T\_BitmapHeapScan}  & Bitmap heap scan - SeqScan with quals                 \\
		scans         & \texttt{T\_CteScan}         & CTE scan - looks up CTE and creates BaseTableOp       \\
		scans         & \texttt{T\_IndexOnlyScan}   & Index-only scan - treated as SeqScan                  \\
		scans         & \texttt{T\_IndexScan}       & Index scan - treated as SeqScan                       \\
		scans         & \texttt{T\_SeqScan}         & Sequential scan - BaseTableOp with optional Selection \\
		scans         & \texttt{T\_SubqueryScan}    & Subquery scan - recursively translates subquery       \\
		utils         & \texttt{T\_Gather}          & Gather workers - pass-through (no parallelism)        \\
		utils         & \texttt{T\_GatherMerge}     & Gather merge - pass-through (no parallelism)          \\
		utils         & \texttt{T\_Hash}            & Hash node - pass-through to child                     \\
		utils         & \texttt{T\_IncrementalSort} & Incremental sort - delegates to Sort                  \\
		utils         & \texttt{T\_Limit}           & Limit/offset - LimitOp with count and offset          \\
		utils         & \texttt{T\_Material}        & Materialize - pass-through (no explicit op)           \\
		utils         & \texttt{T\_Memoize}         & Memoize - pass-through to child                       \\
		utils         & \texttt{T\_Sort}            & Sort operation - SortOp with sort keys                \\
		\bottomrule
	\end{tabular}
	\caption{Plan node translations}
	\label{tab:plan-nodes}
\end{table}

Some common definitions of nodes will also serve to be useful. Nodes commonly
have a \texttt{InitPlan} parameter, which is a function that should be called
before the node is used and contains initiailising variables such as the parameters,
catalogue lookups, or other things. \texttt{targetlist} contains the output
of the node, \texttt{qual} is the qualification of the node, which means
what should be filtered as outputs. Join nodes will have a left and right tree,
with a more intuitive name of inner/outer children. These signify the inner and
outer loops of the nested for-loop that is created.

%-------------------------------------------------------------------------------
\subsubsection{Expression Translation - Variables, Constants, Parameters}\label{subsubsec:expr-vars-consts}
The two relevant ways PostgreSQL identifies values is with variable nodes and
parameter nodes. These are stored inside a schema/column manager class as
well as the \texttt{QueryCtxT} within the code. Variables are typically
defined within scans, while the parameters are intermediate products.
A number of difficulties were encountered with these as there are a number
of interacting variables used to identify them (\texttt{varno}, \texttt{varattno},
and "special" values such as index joins). As a result, a generic function was
built into the QueryCtxT object to handle this lookup logic, \texttt{resolve\_var}.
These will be used constantly.

Parameters are mostly defined within the InitPlan, and one key novel type is
the cached scalar type.

%-------------------------------------------------------------------------------
\subsubsection{Plan translation - Scans}\label{subsubsec:plan-scans}
PostgreSQL has a variety of scans that read from tables, and
handlers for sequential scan, subquery scans, index scans, index-only scans,
bitmap heap scans, and CTE (common table expression) scans were implemented.
However, aside from the subquery scan and CTE scan, they all map to sequential
scan. This is a tradeoff to reduce complexity, and the most impacted
by this is the index scan.

Within the index scan it has specific annotations for variables with its \texttt{INDEX\_VAR}
which requires special resolution mapping to for us to handle. Furthermore,
we need to handle the qualifiers (scan filters) \texttt{indexqual}, \texttt{recheckqual}
like a \texttt{qual}. In psql, these filter at different stages, but since we are
skipping the index implementation they become generic filters instead.

CTE scan plans are defined within the InitPlan of nodes, but still route through
the primary plan switch statement logic. Neither CTE plans or subqueries
currently offer de-duplication to simplify implementation. That is, if a query
uses the same CTE reference or writes the same subquery twice, they will
currently be lowered into two different LLVM chunks of code rather than
congregated and referenced.

%-------------------------------------------------------------------------------
\subsubsection{Plan translation - Aggregations}\label{subsubsec:plan-aggregations}
Aggregation is a complicated node type. It consists of an aggregation strategy,
which is ignored as we have a simple algorithm instead, splitting specification,
which is also unutilised, group columns, number of groups, it can produce
parameters, and it has its own operators such as COUNT, SUM, and so on.
Furthermore, it uses special varnos to do lookups for variables (-2),
so it requires a new context object, and supports DISTINCT statements.

Most of the pain was with specific edge cases that arise in the
simplification. For instance, \texttt{COUNT(*)} behaves differently in combining
mode where parallel workers provide partial counts rather than raw rows,
requiring translation to SUM instead of CountRowsOp. Similarly,
\texttt{HAVING} clauses can reference aggregates not present in the SELECT list,
necessitating a discovery pass with \texttt{find\_all\_aggrefs()} to ensure
all required aggregates are computed before filtering. The use of magic
number varno=-2 to identify aggregate references, while necessary
to distinguish them from regular column references, breaks the normal
variable resolution flow and requires special handling throughout
the expression translator.

%-------------------------------------------------------------------------------
\subsubsection{Plan translation - Joins}\label{subsubsec:plan-joins}
For joins, there are two layers to translating them: the type of join, and
the algorithm used by the join. The type of join refers to inner, semi, anti,
right-anti, left/right joins, and full joins. The semi and anti join types are
not specifically translated, and instead rely on an \texttt{EXISTS}/
\texttt{NOT EXISTS} translations instead because they are semantically the same
operation.

The algorithm used by the join refers to merge, nestloop, or hash joins. Following
LingoDB's pattern, the merge joins are turned into hash joins so that
there does not have to be additional lowering code. A challenge was that
nest loops can carry parameters, so a new query context has to be created,
the parameter has to be registered and inserted into the lookups.

One issue that is still inside the joins implementations is how preventing
double computations works. For this, LingoDB takes the inner join and does
it on its own and builds a vector of results, then afterwards it iterates over
the outer operation and uses the inner section in a pre-computed way. This prevents
duplicated computation at the cost of using more memory. In theory this is fine,
but the vector still needs to implement disk spillage. In practice, this did not
cause enough memory issues to warrant implementation.
%-------------------------------------------------------------------------------
\subsubsection{Expression Translation - Nullability}\label{subsubsec:expr-nullability}
Postgres has nullability defined in the plan tree that is passed to pgx-lower,
but LingoDB appeared to have operations inside the lowerings where previously
non-null objects could become nullable (outer joins, aggregations, unions,
predicate evaluation can all cause this). Since nullability affects every
object and functions in the same way as not-a-number (anything it touches becomes
NaN/nullable), this introduce implementation pains.

One note to be aware of is that LingoDB and PostgreSQL have inverted null flags.
That is, in LingoDB 1 means valid, and in PostgreSQL 1 means null. This
causes confusion with the runtime functions needing to invert flags back and
forth.

%-------------------------------------------------------------------------------
\subsubsection{Expression Translation - Operators and OID strings}\label{subsubsec:expr-operators}
Within operators, the primary challenge is the type conversions and quirks.
Comparing two BPCHARs requires adding padding for the space around them,
and to implicitly upcast operations a class was extracted from LingoDB's
DB dialect (\texttt{SQLTypeInference}). Furthermore, rather than relying on
PostgreSQL's OID system for finding which operation to use, they were
converted to strings (">", "<", and so on) then these were used. This prevents
issues with precision specifications in the OID leading to unidentified
operations, and a similar approach was used in function nodes, aggregation functions,
sort operations, and scalar maths.

%-------------------------------------------------------------------------------
\subsubsection{Translation - Others}\label{subsubsec:expr-operators}
A large number of these nodes are pass through nodes or delegated to another,
sibling node, such as \texttt{T\_Hash}, \texttt{T\_Material},
\texttt{T\_Memoize}, and \texttt{T\_RelabelType}. Furthermore, nodes
also come with executor hints and cost metrics which were skipped over rather
than dragged through LingoDB, as the optimisations were already done by
Postgres. IN/ANY operations are also converted into EXISTS operations,
a number of operations such as scalar subqueries are always marked as nullable,
and CastOps are also made frequently to defer casting to later layers.

%===============================================================================
\subsection{Configuring JIT compilation settings}\label{subsec:jit-config}
Not much tinkering was done with the JIT optimisation flags, the minimum
optimisation passes were used so that it can compile end-to-end, and
\texttt{llvm::CodeGenOptLevel::Default} was used as the optimisation level.
These optimisation passes consist of SROA, InstCombinePass, PromotePass,
LICM pass, reassociation pass, GVN pass, and simplify GVN pass.
The general consensus appeared to be that \texttt{-O2} should be used on it
and moved on. This means it is possible to do more tuning work on this.
% TODO: Define these passes.

%===============================================================================
\subsection{Profiling Support}\label{subsec:profiling}
Code infrastructure was written to support magic-trace for profiling and
isolating issues, and a physical computer with an Intel CPU was set up
with an i5-6500T, 16GB of RAM and a Samsung MZVLB256HAHQ-000L7 NVMe disk.
This was particularly useful for isolating obvious bottlenecks
within the system and understanding the latency when compared to PostgreSQL.
Figure~\ref{fig:psql-magic} represents the flame chart for query 3, and has a
runtime of approximately 260 milliseconds. The functions that it calls are clear,
and you can see how the query runs over time.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.2]{figures/psql-q03-magictrace.png}
	\caption{PostgreSQL's magic-trace flame chart for TPC-H query 3 at scale factor 0.05 (approximately 5 megabytes of data)}
	\label{fig:psql-magic}
\end{figure}

The flame chart before any optimisations were applied is visible in
figure~\ref{fig:pgx-magic-before}. In that chart it is visible that too much
time is spent inside the LLVM execution (those spikes in the last 2/3rds are
table reads). After adjusting how tuples are read, ensuring joins go to the
correct algorithm, introducing Postgres's tuple-slot reading API, and disabling
logs, the chart looks like figure~\ref{fig:pgx-magic-after}. These adjustments
improved the latency from 4.5 seconds to approximately 400 milliseconds.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.2]{figures/pgx-lower-before-q03.png}
	\caption{pgx-lower's magic-trace flame chart for TPC-H query 3 at scale factor 0.05 before optimisation}
	\label{fig:pgx-magic-before}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.2]{figures/pgx-lower-after-q03.png}
	\caption{pgx-lower's magic-trace flame chart for TPC-H query 3 at scale factor 0.05 after optimisation}
	\label{fig:pgx-magic-after}
\end{figure}

The specifics of running these in a stable way will be explained in
subsection~\ref{subsec:benchmarking}.

%===============================================================================
\subsection{Website}\label{subsec:website}
A small website was prepared so that users can interact with the lowerings and
the compiler without installing the system themselves at \url{https://pgx.zyros.dev/query}.
Keep in mind that it relies on caching the results, it has a scale factor of 0.01
(10 megabytes of data), and the pgx-lower system there is (as of writing),
running a debug build which has significantly longer runtimes. The
implementation for this can be is at \url{https://github.com/zyros-dev/pgx-lower-addons}.
It is implemented with python for the backend server. SQLite for the query caching,
react for the frontend, has docker containers to support the reverse proxy
with Nginx, and a private Grafana health dashboard.

%===============================================================================
\subsection{Benchmarking and Validation}\label{subsec:benchmarking}
A challenge is that PostgreSQL contains a non-deterministic optimiser,
and many small factors can affect runs. For this reason, a python script
was created that reads from a yaml file, and does a benchmark run.
This means we can specify runs beforehand, and run them robustly over a long
period. Also, this benchmarking run computes a hash of the outputs
between PostgreSQL and pgx-lower to validate the outputs are correct between
all the runs, and the hashes were compared. This avoids storing large
amounts of data over time, while the issue can still be rediscovered in
a large batch of runs.

The benchmark configurations used are displayed in Listing~\ref{lst:benchmark-config}.
These configurations allow testing across different scale factors, with and without
indexes, and with varying iteration counts to understand performance characteristics.
With multiple iterations, graphs that contain distributions can be created.
These were decided by bucketing queries into small scale factor (0.01, or 1 megabyte
of data) to show the overhead cost of the JIT compiler, medium scale factor
(0.16) to show how Postgres scales while still keeping all the queries enabled
with indexes, and lastly scale factor 1 with the very time-consuming queries
completely disabled. These disabled queries would take on the order of hours in
PostgreSQL, so benchmarking them was too time-consuming.

To disable indexes, \texttt{cur.execute("SET enable\_indexscan = off;")} and
\texttt{cur.execute("SET enable\_bitmapscan = off;")} were used in conjunction.
This means when the benchmarks say index scan is disabled, the bit map scan 
is as well.

\begin{lstlisting}[caption={Benchmark configurations for TPC-H testing},label={lst:benchmark-config}]
full:
  runs:
    - container: benchmark
      scale_factor: 0.01
      iterations: 5
      profile: false
      indexes: false
      skipped_queries: ""
      label: "SF=0.01, indexes disabled, 5 iterations"

    - container: benchmark
      scale_factor: 0.01
      iterations: 100
      profile: false
      indexes: false
      skipped_queries: "q07,q20"
      label: "SF=0.01, indexes disabled - excluding postgres {q07,q20}, 100 iterations"

    - container: benchmark
      scale_factor: 0.01
      iterations: 100
      profile: false
      indexes: true
      skipped_queries: ""
      label: "SF=0.01, indexes enabled, 100 iterations"

    - container: benchmark
      scale_factor: 0.16
      iterations: 5
      profile: false
      indexes: true
      skipped_queries: ""
      label: "SF=0.16, indexes enabled, 5 iterations"

    - container: benchmark
      scale_factor: 0.16
      iterations: 100
      profile: false
      indexes: true
      skipped_queries: "q17,q20"
      label: "SF=0.16, indexes enabled, excluding {q17,q20}, 100 iterations"

    - container: benchmark
      scale_factor: 1
      iterations: 100
      profile: false
      indexes: false
      skipped_queries: "q02,q17,q20,q21"
      label: "SF=1, indexes disabled, excluding {q02,q17,q20,q21}, 100 iterations"
\end{lstlisting}

One thing to note here is that it was decided that only PostgreSQL and pgx-lower
would be compared, rather than all the databases mentioned in
chapter~\ref{ch:related-work}. As section~\ref{sec:benchmarking} showed that
the impact of PostgreSQL's architecture being on disk makes it significantly
slower than any of the other databases.

The magic trace profiling also functions through this script, which is
what the \texttt{profile} tag there is for.