\chapter{Results and Discussion}\label{ch:results}
\section{Results}\label{sec:results}

Results using the method from subsection~\ref{subsec:benchmarking} were produced as follows.
Box plots overlaid on graphs represent the 5th, 25th, 50th,
75th, and 95th percentiles. Hollow circles mark outliers; when inconvenient to display
(as in figure~\ref{fig:bench-mem-diff-plots}), arrow annotations are used
instead. Matplotlib and Seaborn generated all visualizations in Python.

Another result worth mentioning is the integrated LingoDB code
(including ./src/lingodb and ./include/lingodb) contains 13,875 lines of C++,
while the pgx-lower section (./src/pgx-lower and ./include/pgx-lower contains
12,324 lines of C++. This was measured with tokei commands, a command line
utility for counting lines of code. In comparison, the official PostgreSQL
executor is roughly 82,875 lines of code, and LingoDB is roughly 30,000 lines
of code \cite{lingo-db-1,postgresql_source}.

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.32]{figures/mine_box_plots.pdf}
	\caption{Overall benchmarking represented with box plots}
	\label{fig:bench-box-plots}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.32]{figures/mine_diff_plots.pdf}
	\caption{Difference in latency benchmarks between PostgreSQL and pgx-lower}
	\label{fig:bench-diff-plots}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.32]{figures/mine_memory_plots.pdf}
	\caption{Peak memory usage of queries}
	\label{fig:bench-mem-plots}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.32]{figures/mine_memory_diffs.pdf}
	\caption{Difference in peak memory usage of queries}
	\label{fig:bench-mem-diff-plots}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.32]{figures/mine_branch_miss_plots.pdf}
	\caption{Branch miss rate}
	\label{fig:branch-miss-plot}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.32]{figures/mine_branches_plots.pdf}
	\caption{Number of branches}
	\label{fig:num-branch-plot}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.32]{figures/mine_llc_miss_plots.pdf}
	\caption{Last-level-cache miss plots}
	\label{fig:llc-miss-plot}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.32]{figures/mine_ipc_plots.pdf}
	\caption{Instructions per (CPU) cycle plot}
	\label{fig:ipc-plot}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.15]{figures/q20-index-on-sf0.16-psql.png}
	\caption{PostgreSQL TPC-H query 20 indexes enabled at SF = 0.16. Runtime: 15 minutes}
	\label{fig:q20-psql-profile}
\end{figure}
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.15]{figures/q20-pgx-profile.png}
	\caption{pgx-lower TPC-H query 20 indexes enabled at SF = 0.16. Runtime: 1.18 seconds}
	\label{fig:q20-pgx-profile}
\end{figure}

\section{Discussion}\label{sec:Discussion}
To reiterate, the goal is to show that using the extension system is a viable
approach to introduce compiled queries into battle-tested databases while
maintaining their ACID properties. Previous studies have already found that
this model has speed benefits.

In terms of latency, results are mixed.
Figures~\ref{fig:bench-box-plots} and~\ref{fig:bench-diff-plots} show that without indexes at scale factor 0.01,
queries 7 and 20 are orders of magnitude slower than other queries.
Such patterns repeat at scale factor 0.16 even with indexes enabled.
In contrast, pgx-lower shows consistent performance across these queries. Visible in
figures~\ref{fig:q20-psql-profile} and~\ref{fig:q20-pgx-profile}, the difference appears: PostgreSQL uses nested loop joins
while pgx-lower uses hash joins.
Appendices~\ref{appendix:q20-sql},~\ref{appendix:q20-postgres}, and~\ref{appendix:q20-pgxlower} show the query and both systems' plan trees. In pgx-lower's output,
joins are annotated with "hash", indicating hash join usage. This comparison
is not entirely fair because pgx-lower uses a hash join while PostgreSQL uses
a nested loop join (NestLoop\_T), which would benefit from indexing.

Figure~\ref{fig:q20-pgx-profile} reveals minimal time spent in LLVM code generation. Of the 1.18 second total query execution time,
only 15 milliseconds occurs in \texttt{llvm::SelectionDAGISel::runOnMachineFunction}, the LLVM IR to machine code conversion step. Total compilation
time reaches 236 milliseconds, with most spent in MLIR passes. These results suggest
MLIR optimization is more expensive than LLVM code generation. Possibly the LLVM ORC JIT does minimal work for each query, spreading compilation across background execution.

RAM usage appears similar between pgx-lower and PostgreSQL (figures~\ref{fig:bench-mem-plots} and~\ref{fig:bench-mem-diff-plots}).
Such similarity demonstrates successful adaptation of LingoDB's in-memory operations to PostgreSQL's disk-oriented architecture. Maximum difference is just over 3 MB, with a mean difference of 0.34 MB across all queries.

Branch prediction potential appears in figure~\ref{fig:branch-miss-plot}.
At scale factor 1, pgx-lower achieved a median
branch miss rate of 0.16\%, compared to PostgreSQL's 0.28\%. However,
smaller scale factors with smaller queries inverted this: PostgreSQL had 0.38\% and pgx-lower had 1.09\%. Such results suggest
the compiled JIT runtime has better branch prediction, but
the compilation stage or pre-warm-up code has worse prediction.
Number of branches explains part of the difference (figure~\ref{fig:num-branch-plot}): PostgreSQL had 28,430,465
median branches, while pgx-lower had 195,299,021.50 (6.87 times more).
Higher branch counts could indicate more optimization opportunities.

For the last level cache miss rate, pgx-lower appears to perform better than
PostgreSQL at smaller scale factors and appears similar to PostgreSQL at larger
ones, which can be seen in figure~\ref{fig:llc-miss-plot}. PostgreSQL
has a median 31.20\% miss rate at scale factor 0.01, while pgx-lower has a
median of 6.19\%. When increased to a scale factor of 1, PostgreSQL has a median
of 33.16\%, and pgx-lower has a median of 34.81\%. A likely explanation: the LLVM compiler stage uses its cache much more effectively, but the
actual JIT runtime performs comparably. Expected with the current approach,
improvements would emerge if the JIT stage dynamically changed
the plan, similar to HyPer's approach.

\subsection{Test Validity}\label{subsec:test-validity}
Increasing the number of iterations to make the outputs more reliable seems to
be successful, and the variation is not too large. Some queries, such as in
scale factor 0.01 with indexes disabled, in figure~\ref{fig:bench-box-plots},
show the outliers do become extreme. On query 8, PostgreSQL had an outlier
of 5008 milliseconds while the median was 12.42 milliseconds. However, the
coefficient of variation was only 0.4\% overall during the
latency measurements in the scale factor 0.01. It's stable overall,
but vital to do repeated tests to exclude these outliers from the system.

These variations will primarily be caused by PostgreSQL's optimiser containing
genetic algorithms, as mentioned in section~\ref{sec:postgresql-background}. It
can cause plans to change significantly and makes them non-deterministic.
While these tests were done on an isolated docker container in a Linux machine
running minimal processes, system interrupts can also affect the results.

\subsection{Future work}\label{subsec:future-work}
Replacing PostgreSQL's execution engine with a JIT-focused approach offers multiple research directions. Improvements can be made by fully implementing the plan nodes and
optimising further. However, ensuring the final product remains useful requires considering
other base databases, compilers, languages, and compatible
execution engines.

Full extension implementation requires complete plan tree
node implementation and query analyser improvements.
Only the minimum for TPC-H was implemented, requiring pg\_bench
and isolationtester validation before user deployment.
Needed additions include indexes, WINDOW functions, the other
22 missing plan nodes, and missing execution nodes.

Core optimization work involves leveraging existing research and clearer PostgreSQL API usage. Key improvements include: pre-compiling
PostgreSQL functions into LLVM, then inlining instead of
crossing the LLVM-C++ boundary; adaptive compilation/query planning;
and Umbra's LeanStore-style buffering. Most
optimisations apply specifically to
LLVM/MLIR systems; WebAssembly alternatives could skip
many of these. Broader improvements include parallelism enhancement,
JIT tuning, cross-platform support, subquery
deduplication, and further optimisations.

Research impact remains vital in database systems, reflecting Michael Stonebraker's concern about field progress~\cite{top-ten-fears}. For
successful projects, database costs are typically minor relative to overall profitability,
making higher throughput less critical. Practically, latency gains more often come from application-level caching (like Redis) than database optimization.
Complex OLAP queries often run on large-scale systems that migrate away from PostgreSQL to more scalable
databases such as ClickHouse or Apache Hive. Alternative systems may provide better development platforms for this architecture.

PostgreSQL was selected for its large popularity; LingoDB was chosen because it matched PostgreSQL's interfaces while remaining open source.
While PostgreSQL works reasonably for this approach and addresses real problems, better alternatives may exist. Most dedicated
OLAP systems already employ JIT or vectorized approaches.

Development with LingoDB provided helpful constraints and faster iteration due to its established nature. However, LingoDB's
columnar, in-memory architecture required extensive modifications. Additionally, its redundant query optimisation engine was unnecessary since
PostgreSQL already provides thorough optimization. A better approach would involve building the engine from scratch or selecting a more suitable base system.
Umbra would be ideal based on its description, but closed-source status prevents use. Alternative approaches could integrate an established OLAP system's
engine (such as ClickHouse), routing queries based on analyser rules instead of using PostgreSQL's executor.

MLIR was useful to give a strong set of dialect systems, but the main reason
LingoDB used it was to give database optimisations clear layers. Furthermore,
the LLVM/MLIR ecosystem targets ahead of time compilation, or longer-running
JIT systems. While WebAssembly is appealing here because it targets
short-lived processes, we would not be able to inline functions in the future.
Either way, switching to a different compiler, or away from C++ into C or
Rust is appealing.

Multiple promising research directions emerge from this work.
Most appealing is integrating NoisePage or ClickHouse
into PostgreSQL as a drop-in engine replacement.
Such an approach provides a more complete ecosystem; primary work will focus on
adapters to adjust queries. Furthermore, pg\_duckdb has already done
this, but it is a vectorised engine.
